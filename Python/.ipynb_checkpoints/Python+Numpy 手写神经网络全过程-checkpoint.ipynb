{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:3em; text-align: center; \"><b> Python+Numpy 手写神经网络全过程 </b></p>\n",
    "\n",
    "<p style=\"font-size:2em; text-align: center;\">1.大家工作都是做什么的？</p>\n",
    "\n",
    "<p style=\"font-size:2em; text-align: center;\">2.大家对人工智能了解多少？</p>\n",
    "\n",
    "<p style=\"font-size:2em; text-align: center;\">\n",
    "    <li style=\"font-size:1.5em; text-align: center;\">0: 只听说过</li>\n",
    "    <li style=\"font-size:1.5em; text-align: center;\">1: 编过程，但是没写过人工智能的程序</li>\n",
    "    <li style=\"font-size:1.5em; text-align: center;\">2: 写过人工智能的程序，但是不太6</li>\n",
    "    <li style=\"font-size:1.5em; text-align: center;\">3: 在做人工智能相关的工作</li>\n",
    "</p>\n",
    "\n",
    "<section class=\"page\">\n",
    "<!--   <hr class=\"dashed-divider\" /> -->\n",
    "  <div class=\"repeating-divider\"></div>\n",
    "  <img class=\"image-divider\"\n",
    "       src=\"http://aimaksen.bslience.cn/dividing-1.png\" />\n",
    "  <div class=\"border-image-divider\"></div>\n",
    "</section>\n",
    "\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/neural-network-scratch.jpg\">\n",
    "</p>\n",
    "\n",
    "- 纯 Python + Numpy\n",
    "- 学习深度学习底层的原理，当我们以后用框架的时候，能够更好的知道框架在做什么\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section class=\"page\">\n",
    "<!--   <hr class=\"dashed-divider\" /> -->\n",
    "  <div class=\"repeating-divider\"></div>\n",
    "  <img class=\"image-divider\"\n",
    "       src=\"http://aimaksen.bslience.cn/dividing-1.png\" />\n",
    "  <div class=\"border-image-divider\"></div>\n",
    "</section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自我介绍\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/cyang-info.jpg\">\n",
    "</p>\n",
    "\n",
    "**我的一些项目经历**\n",
    "\n",
    "- 百度手机助手推荐系统\n",
    "- 百度 IP 魔方，IP 预测\n",
    "- 新东方人功智能教育系统（参与了整个系统从零搭建的过程）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抽奖预告\n",
    "\n",
    "\n",
    "\n",
    "<section class=\"page\">\n",
    "<!--   <hr class=\"dashed-divider\" /> -->\n",
    "  <div class=\"repeating-divider\"></div>\n",
    "  <img class=\"image-divider\"\n",
    "       src=\"http://aimaksen.bslience.cn/dividing-1.png\" />\n",
    "  <div class=\"border-image-divider\"></div>\n",
    "</section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练营安排\n",
    "\n",
    "\n",
    "### 第一天 实现第一个神经网络层\n",
    "- 神经网络原理介绍\n",
    "- 神经元介绍和代码编写\n",
    "- 实现神经网络中的一层 Layer\n",
    "- 作业：使用 Python 和 Numpy 编写 Layer 层\n",
    "\n",
    "### 第二天 多层神经网络和激活函数的实现\n",
    "- 多层网络中点乘的原理与实现\n",
    "- 批处理(Batch) 的原理和实现\n",
    "- Layer 面向对象的抽象\n",
    "- 隐藏层中激活函数的实现\n",
    "- Softmax 激活函数的实现\n",
    "- 作业：完成多层计算和 Softmax 激活函数\n",
    "\n",
    "### 第三天 反向传播算法和参数更新的实现\n",
    "- 使用 Cross-entropy 计算损失\n",
    "- 优化函数的实现与自动求导\n",
    "- 抽象属于你的面向对象框架\n",
    "- 作业：完整神经网络的实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section class=\"page\">\n",
    "<!--   <hr class=\"dashed-divider\" /> -->\n",
    "  <div class=\"repeating-divider\"></div>\n",
    "  <img class=\"image-divider\"\n",
    "       src=\"http://aimaksen.bslience.cn/dividing-1.png\" />\n",
    "  <div class=\"border-image-divider\"></div>\n",
    "</section>\n",
    "\n",
    "\n",
    "<p style=\"font-size:3em; text-align: center; \"><b> 第一天 </b></p>\n",
    "\n",
    "\n",
    "- 神经网络原理介绍\n",
    "- 神经元介绍和代码编写\n",
    "- 实现神经网络中的一层 Layer\n",
    "- 作业：使用 Python 和 Numpy 编写 Layer 层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础环境安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mlt\n",
    "import numpy as np\n",
    "\n",
    "print(sys.version)\n",
    "print(np.__version__)\n",
    "print(mlt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetstore==1.0.1.7\n",
      "  Downloading datasetstore-1.0.1.7.tar.gz (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 308 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: aiobotocore==1.2.2 in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (1.2.2)\n",
      "Requirement already satisfied: boto3==1.16.28 in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (1.16.28)\n",
      "Requirement already satisfied: s3fs==0.6.0 in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (0.6.0)\n",
      "Collecting datasets==2.5.1\n",
      "  Downloading datasets-2.5.1-py3-none-any.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 555 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: yaspin in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (2.2.0)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (5.0.1)\n",
      "Requirement already satisfied: plotly==5.10.0 in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (5.10.0)\n",
      "Requirement already satisfied: cufflinks in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (0.17.3)\n",
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (1.8.1)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (0.10.3)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (1.7.4)\n",
      "Requirement already satisfied: matplotlib==3.2.2 in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (3.2.2)\n",
      "Requirement already satisfied: statsmodels==0.13.2 in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (0.13.2)\n",
      "Requirement already satisfied: pandas-profiling[notebook] in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (2.13.0)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (2.1.0)\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.8/site-packages (from datasetstore==1.0.1.7) (0.42.1)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.8/site-packages (from aiobotocore==1.2.2->datasetstore==1.0.1.7) (1.12.1)\n",
      "Requirement already satisfied: botocore<1.19.53,>=1.19.52 in /opt/conda/lib/python3.8/site-packages (from aiobotocore==1.2.2->datasetstore==1.0.1.7) (1.19.52)\n",
      "Requirement already satisfied: aiohttp>=3.3.1 in /opt/conda/lib/python3.8/site-packages (from aiobotocore==1.2.2->datasetstore==1.0.1.7) (3.7.4.post0)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.8/site-packages (from aiobotocore==1.2.2->datasetstore==1.0.1.7) (0.11.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from boto3==1.16.28->datasetstore==1.0.1.7) (0.3.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3==1.16.28->datasetstore==1.0.1.7) (0.10.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (1.2.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (2022.8.2)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (2.25.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (3.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (1.19.5)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==2.5.1->datasetstore==1.0.1.7) (9.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->datasetstore==1.0.1.7) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->datasetstore==1.0.1.7) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->datasetstore==1.0.1.7) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib==3.2.2->datasetstore==1.0.1.7) (2.8.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from plotly==5.10.0->datasetstore==1.0.1.7) (6.3.1)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.8/site-packages (from statsmodels==0.13.2->datasetstore==1.0.1.7) (1.7.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.8/site-packages (from statsmodels==0.13.2->datasetstore==1.0.1.7) (0.5.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp>=3.3.1->aiobotocore==1.2.2->datasetstore==1.0.1.7) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp>=3.3.1->aiobotocore==1.2.2->datasetstore==1.0.1.7) (1.5.1)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp>=3.3.1->aiobotocore==1.2.2->datasetstore==1.0.1.7) (3.0.1)\n",
      "Requirement already satisfied: chardet<5.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp>=3.3.1->aiobotocore==1.2.2->datasetstore==1.0.1.7) (4.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp>=3.3.1->aiobotocore==1.2.2->datasetstore==1.0.1.7) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp>=3.3.1->aiobotocore==1.2.2->datasetstore==1.0.1.7) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.19.53,>=1.19.52->aiobotocore==1.2.2->datasetstore==1.0.1.7) (1.26.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib==3.2.2->datasetstore==1.0.1.7) (1.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.5.1->datasetstore==1.0.1.7) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.5.1->datasetstore==1.0.1.7) (5.4.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==2.5.1->datasetstore==1.0.1.7) (2021.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.5.1->datasetstore==1.0.1.7) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==2.5.1->datasetstore==1.0.1.7) (2021.5.30)\n",
      "Requirement already satisfied: colorlover>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from cufflinks->datasetstore==1.0.1.7) (0.3.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.8/site-packages (from cufflinks->datasetstore==1.0.1.7) (7.6.3)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /opt/conda/lib/python3.8/site-packages (from cufflinks->datasetstore==1.0.1.7) (49.6.0.post20210108)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from cufflinks->datasetstore==1.0.1.7) (7.24.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (3.0.19)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.17.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (5.0.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (4.4.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.1.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.2.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (2.9.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (5.5.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (3.5.1)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (6.2.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (4.7.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.17.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->cufflinks->datasetstore==1.0.1.7) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (6.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (22.1.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (5.6.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.10.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.11.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (3.0.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (1.7.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (1.5.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (2.0.1)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (3.3.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks->datasetstore==1.0.1.7) (0.5.1)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (0.1.12)\n",
      "Requirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (0.5.0)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (0.1.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (0.11.1)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.1 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (0.7.1)\n",
      "Requirement already satisfied: confuse>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (1.5.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (1.0.1)\n",
      "Requirement already satisfied: phik>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from pandas-profiling[notebook]->datasetstore==1.0.1.7) (0.11.2)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling[notebook]->datasetstore==1.0.1.7) (2.5.1)\n",
      "Requirement already satisfied: multimethod==1.4 in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling[notebook]->datasetstore==1.0.1.7) (1.4)\n",
      "Requirement already satisfied: bottleneck in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling[notebook]->datasetstore==1.0.1.7) (1.3.2)\n",
      "Requirement already satisfied: imagehash in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling[notebook]->datasetstore==1.0.1.7) (4.2.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from visions[type_image_path]==0.7.1->pandas-profiling[notebook]->datasetstore==1.0.1.7) (8.2.0)\n",
      "Requirement already satisfied: PyWavelets in /opt/conda/lib/python3.8/site-packages (from imagehash->visions[type_image_path]==0.7.1->pandas-profiling[notebook]->datasetstore==1.0.1.7) (1.1.1)\n",
      "Requirement already satisfied: termcolor-whl==1.1.2 in /opt/conda/lib/python3.8/site-packages (from yaspin->datasetstore==1.0.1.7) (1.1.2)\n",
      "Building wheels for collected packages: datasetstore\n",
      "  Building wheel for datasetstore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for datasetstore: filename=datasetstore-1.0.1.7-py3-none-any.whl size=49731 sha256=1ce8ff491deba7ef60b2195e109e9b5a26fd3a27540a78f89e75316ac67ff75d\n",
      "  Stored in directory: /root/.cache/pip/wheels/f9/96/0d/0867708053098f46fdb8a93805f94316c6aa791dd52cb63a84\n",
      "Successfully built datasetstore\n",
      "Installing collected packages: datasets, datasetstore\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "  Attempting uninstall: datasetstore\n",
      "    Found existing installation: datasetstore 1.0.1.5\n",
      "    Uninstalling datasetstore-1.0.1.5:\n",
      "      Successfully uninstalled datasetstore-1.0.1.5\n",
      "Successfully installed datasets-2.5.1 datasetstore-1.0.1.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install datasetstore==1.0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetstore.eda.video import video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络介绍\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/neural-network.jpg\">\n",
    "</p>\n",
    "\n",
    "\n",
    "### 多层神经网络演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Example%20Models%20(NTR%200001B).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Example%20Models%20(NTR%200001B).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个神经元的工作原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/How%20weights%20and%20biases%20impact%20a%20single%20neuron%20(BRU%200038).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/How%20weights%20and%20biases%20impact%20a%20single%20neuron%20(BRU%200038).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HR style=\"border:3 double #987cb9\" width=\"80%\" color=#987cb9 SIZE=3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dogs vs Cats 的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Model%202x4%20Cats%20Dogs%20(QTB%200004).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Model%202x4%20Cats%20Dogs%20(QTB%200004).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 背后的数学公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/The%20math%20behind%20an%20example%20forward%20pass%20through%20a%20neural%20network%20(VKT%200005).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/The%20math%20behind%20an%20example%20forward%20pass%20through%20a%20neural%20network%20(VKT%200005).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Model%202x4%20Cats%20Dogs%20Code%20(VKR%200005B).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/Model%202x4%20Cats%20Dogs%20Code%20(VKR%200005B).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始写我们的第一个神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "output = inputs[0] * weights[0] + inputs[1] * weights[1] + inputs[2] * weights[2] + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Single%20Neuron%20(BKR%200026).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Single%20Neuron%20(BKR%200026).mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "output = (\n",
    "    inputs[0] * weights[0]\n",
    "    + inputs[1] * weights[1]\n",
    "    + inputs[2] * weights[2]\n",
    "    + inputs[3] * weights[3]\n",
    "    + bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Single%20Neuron%202%20(0027).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Single%20Neuron%202%20(0027).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一层神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Four%20Neurons%20(MXO%200028).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Four%20Neurons%20(MXO%200028).mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights1 = [0.2, 0.8, -0.5, 1]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "outputs = [\n",
    "    # Neuron 1:\n",
    "    inputs[0] * weights1[0]\n",
    "    + inputs[1] * weights1[1]\n",
    "    + inputs[2] * weights1[2]\n",
    "    + inputs[3] * weights1[3]\n",
    "    + bias1,\n",
    "    # Neuron 2:\n",
    "    inputs[0] * weights2[0]\n",
    "    + inputs[1] * weights2[1]\n",
    "    + inputs[2] * weights2[2]\n",
    "    + inputs[3] * weights2[3]\n",
    "    + bias2,\n",
    "    # Neuron 3:\n",
    "    inputs[0] * weights3[0]\n",
    "    + inputs[1] * weights3[1]\n",
    "    + inputs[2] * weights3[2]\n",
    "    + inputs[3] * weights3[3]\n",
    "    + bias3,\n",
    "]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of current layer\n",
    "layer_outputs = []\n",
    "# For each neuron\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    # Zeroed output of given neuron\n",
    "    neuron_output = 0\n",
    "    # For each input and weight to the neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        # Multiply this input by associated weight\n",
    "        # and add to the neuron's output variable\n",
    "        neuron_output += n_input * weight\n",
    "    # Add bias\n",
    "    neuron_output += neuron_bias\n",
    "    # Put neuron's result to the layer's output list\n",
    "    layer_outputs.append(neuron_output)\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改写成张量(tensors)的形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 什么是 tensor？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Array%20Shape%20(JPS%200036).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Array%20Shape%20(JPS%200036).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 点乘(Dot Product) 和向量相加(Vector Addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/nnf/dot-product-formula.jpg\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "\n",
    "dot_product = a[0] * b[0] + a[1] * b[1] + a[2] * b[2]\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Dot%20Product%20(XPO%200029).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Dot%20Product%20(XPO%200029).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 Numpy 实现单个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Dot%20Product%20Neuron%20(BLQ%200030).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Dot%20Product%20Neuron%20(BLQ%200030).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 Numpy 实现一层神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Dot%20Product%20Layer%20(CYX%200031).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Dot%20Product%20Layer%20(CYX%200031).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section class=\"page\">\n",
    "<!--   <hr class=\"dashed-divider\" /> -->\n",
    "  <div class=\"repeating-divider\"></div>\n",
    "  <img class=\"image-divider\"\n",
    "       src=\"http://aimaksen.bslience.cn/dividing-1.png\" />\n",
    "  <div class=\"border-image-divider\"></div>\n",
    "</section>\n",
    "\n",
    "\n",
    "<p style=\"font-size:3em; text-align: center; \"><b> 第二天 </b></p>\n",
    "\n",
    "- 批处理(Batch) 的原理和实现\n",
    "- Layer 面向对象的抽象\n",
    "- 多层网络中点乘的原理与实现\n",
    "- 隐藏层中激活函数的实现\n",
    "- Softmax 激活函数的实现\n",
    "- 作业：完成多层计算和 Softmax 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Batch%20of%20Samples%200037.mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Batch%20of%20Samples%200037.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么要一次处理批量的数据呢？\n",
    "\n",
    "- 一个原因是并行处理分批训练更快\n",
    "- 另一个原因是在训练过程中帮助泛化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Why%20To%20Use%20Batches%20(VYU%200040).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Why%20To%20Use%20Batches%20(VYU%200040).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20(JEI%200032).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20(JEI%200032).mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入和权重的矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20Inputs%20Weights%20(BKW%200033).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20Inputs%20Weights%20(BKW%200033).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法中的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Transposition%20%20(QUT%200002B).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Transposition%20%20(QUT%200002B).mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Transposition%20(pnq%200002).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/Transposition%20(pnq%200002).mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3]]),\n",
       " array([[2],\n",
       "        [3],\n",
       "        [4]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "a = np.array([a])\n",
    "b = np.array([b]).T\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用转置来实现神经网络批量数据的一层计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Why%20To%20Transpose%20Weights%20(CRQ%200039).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/Why%20To%20Transpose%20Weights%20(CRQ%200039).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5], [2.0, 5.0, -1.0, 2.0], [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20Row%20Column%20Vector%20(GJW%200034).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20Row%20Column%20Vector%20(GJW%200034).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20Addition%20Inputs%20Weights%20Biases%20(QTY%200035).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/Matrix%20Product%20Addition%20Inputs%20Weights%20Biases%20(QTY%200035).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增加更多的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [[1, 2, 3, 2.5], [2.0, 5.0, -1.0, 2], [-1.5, 2.7, 3.3, -0.8]]\n",
    "weights = [[0.2, 0.8, -0.5, 1], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "weights2 = [[0.1, -0.14, 0.5], [-0.5, 0.12, -0.33], [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络层的抽象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnfs\n",
    "import numpy as np\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "# Let's see output of the first few samples:\n",
    "print(dense1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阶跃函数(Step Activation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性激活函数(The Linear Activation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 激活函数(Sigmoid Activation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU 激活函数(Rectified Linear Activation Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么要使用激活函数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/Why%20&%20how%20two%20or%20more%20hidden%20layers%20w_%20nonlinear%20activation%20function%20works%20deep%20learning%20(MVP%200051).mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\n",
    "    \"http://aimaksen.bslience.cn/nnf/Why%20&%20how%20two%20or%20more%20hidden%20layers%20w_%20nonlinear%20activation%20function%20works%20deep%20learning%20(MVP%200051).mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归例子中 ReLU 的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"100%\" height=\"720\" src=\"http://aimaksen.bslience.cn/nnf/ReLU%20Regression%20Demo%2064%200055.mp4\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video(\"http://aimaksen.bslience.cn/nnf/ReLU%20Regression%20Demo%2064%200055.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
    "output = []\n",
    "for i in inputs:\n",
    "    if i > 0:\n",
    "        output.append(i)\n",
    "    else:\n",
    "        output.append(0)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
    "output = []\n",
    "for i in inputs:\n",
    "    output.append(max(0, i))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
    "output = np.maximum(0, inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from input\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "# Make a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "# Forward pass through activation func.\n",
    "# Takes in output from previous layer\n",
    "activation1.forward(dense1.output)\n",
    "print(activation1.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values from the previous output when we described\n",
    "# what a neural network is\n",
    "layer_outputs = [4.8, 1.21, 2.385]\n",
    "# e - mathematical constant, we use E here to match a common coding\n",
    "# style where constants are uppercased\n",
    "E = 2.71828182846  # you can also use math.e\n",
    "# For each value in a vector, calculate the exponential value\n",
    "exp_values = []\n",
    "for output in layer_outputs:\n",
    "    exp_values.append(E ** output)  # ** - power operator in Python\n",
    "print(\"exponentiated values:\")\n",
    "print(exp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now normalize values\n",
    "norm_base = sum(exp_values)  # We sum all values\n",
    "norm_values = []\n",
    "for value in exp_values:\n",
    "    norm_values.append(value / norm_base)\n",
    "print(\"Normalized exponentiated values:\")\n",
    "print(norm_values)\n",
    "print(\"Sum of normalized values:\", sum(norm_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Values from the earlier previous when we described\n",
    "# what a neural network is\n",
    "layer_outputs = [4.8, 1.21, 2.385]\n",
    "# For each value in a vector, calculate the exponential value\n",
    "exp_values = np.exp(layer_outputs)\n",
    "print(\"exponentiated values:\")\n",
    "print(exp_values)\n",
    "# Now normalize values\n",
    "norm_values = exp_values / np.sum(exp_values)\n",
    "print(\"normalized exponentiated values:\")\n",
    "print(norm_values)\n",
    "print(\"sum of normalized values:\", np.sum(norm_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unnormalized probabilities\n",
    "exp_values = np.exp(inputs)\n",
    "# Normalize them for each sample\n",
    "probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:  # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnfs\n",
    "import numpy as np\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:  # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "# Create Softmax activation (to be used with Dense layer):\n",
    "activation2 = Activation_Softmax()\n",
    "# Make a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "# Make a forward pass through activation function\n",
    "# it takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "# Make a forward pass through second Dense layer\n",
    "# it takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "# Make a forward pass through activation function\n",
    "# it takes the output of second dense layer here\n",
    "activation2.forward(dense2.output)\n",
    "# Let's see output of the first few samples:\n",
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section class=\"page\">\n",
    "<!--   <hr class=\"dashed-divider\" /> -->\n",
    "  <div class=\"repeating-divider\"></div>\n",
    "  <img class=\"image-divider\"\n",
    "       src=\"http://aimaksen.bslience.cn/dividing-1.png\" />\n",
    "  <div class=\"border-image-divider\"></div>\n",
    "</section>\n",
    "\n",
    "\n",
    "<p style=\"font-size:3em; text-align: center; \"><b> 第三天 </b></p>\n",
    "\n",
    "\n",
    "- 使用 Cross-entropy 计算损失\n",
    "- 优化函数的实现与自动求导\n",
    "- 抽象属于你的面向对象框架\n",
    "- 作业：完整神经网络的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/nnf/cross-entropy-formula.jpg\">\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/nnf/cross-entropy-log.jpg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "target_value = [1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"http://aimaksen.bslience.cn/nnf/cross-entropy-cal.jpg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# An example output from the output layer of the neural network\n",
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "# Ground truth\n",
    "target_output = [1, 0, 0]\n",
    "loss = -(\n",
    "    math.log(softmax_output[0]) * target_output[0]\n",
    "    + math.log(softmax_output[1]) * target_output[1]\n",
    "    + math.log(softmax_output[2]) * target_output[2]\n",
    ")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -math.log(softmax_output[0])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n",
      "0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "print(-math.log(0.7))\n",
    "print(-math.log(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnfs\n",
    "import numpy as np\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "\n",
    "class Activation_Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilities\n",
    "\n",
    "\n",
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
    "\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])\n",
    "\n",
    "loss_function = Loss_CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
